From a38d8a1e4607fa62293a9b5e622ae3c23c590388 Mon Sep 17 00:00:00 2001
From: John Cox <jc@kynesim.co.uk>
Date: Sat, 1 Oct 2022 12:39:45 +0000
Subject: [PATCH 150/151] vf_deinterlace_v4l2m2m: Ensure we get consistent
 final frames

On getting EOS at the input of the filster do not simply drop everything
in transit on the floor but attempt to retrieve everything possible from
the capture Q before on-signalling EOS.
If we know that we expect 1 frame in to always produce 1 frame out then
match CAPTURE frame to the last OUTPUT frame Qed (scale)
If frames out have an unknown relation to source frames (deinterlace) try
an encode stop and wait for the last frame marker to emerge from CAPTURE
---
 libavfilter/vf_deinterlace_v4l2m2m.c | 172 +++++++++++++++++++++++----
 1 file changed, 148 insertions(+), 24 deletions(-)

diff --git a/libavfilter/vf_deinterlace_v4l2m2m.c b/libavfilter/vf_deinterlace_v4l2m2m.c
index 4ed510cd19..84714246ad 100644
--- a/libavfilter/vf_deinterlace_v4l2m2m.c
+++ b/libavfilter/vf_deinterlace_v4l2m2m.c
@@ -94,6 +94,7 @@ typedef struct V4L2Buffer {
 typedef struct V4L2Queue {
     struct v4l2_format format;
     struct v4l2_selection sel;
+    int eos;
     int num_buffers;
     V4L2Buffer *buffers;
     const char * name;
@@ -127,20 +128,41 @@ typedef struct pts_track_s
     pts_track_el_t a[PTS_TRACK_SIZE];
 } pts_track_t;
 
+typedef enum drain_state_e
+{
+    DRAIN_NONE = 0,     // Not draining
+    DRAIN_TIMEOUT,      // Drain until normal timeout setup yields no frame
+    DRAIN_LAST,         // Drain with long timeout last_frame in received on output expected
+    DRAIN_EOS,          // Drain with long timeout EOS expected
+    DRAIN_DONE          // Drained
+} drain_state_t;
+
 typedef struct DeintV4L2M2MContextShared {
     void * logctx;  // For logging - will be NULL when done
     filter_type_v4l2_t filter_type;
 
     int fd;
-    int done;
+    int done;   // fd closed - awating all refs dropped
     int width;
     int height;
 
+    int drain;          // EOS received (inlink status)
+    drain_state_t drain_state;
+    int64_t drain_pts;  // PTS associated with inline status
+
+    unsigned int frames_rx;
+    unsigned int frames_tx;
+
     // from options
     int output_width;
     int output_height;
     enum AVPixelFormat output_format;
 
+    int has_enc_stop;
+    // We expect to get exactly the same number of frames out as we put in
+    // We can drain by matching input to output
+    int one_to_one;
+
     int orig_width;
     int orig_height;
     atomic_uint refcount;
@@ -179,6 +201,12 @@ typedef struct DeintV4L2M2MContext {
     enum AVChromaLocation chroma_location;
 } DeintV4L2M2MContext;
 
+
+static inline int drain_frame_expected(const drain_state_t d)
+{
+    return d == DRAIN_EOS || d == DRAIN_LAST;
+}
+
 // These just list the ones we know we can cope with
 static uint32_t
 fmt_av_to_v4l2(const enum AVPixelFormat avfmt)
@@ -334,6 +362,13 @@ fail:
     return 0;
 }
 
+// We are only ever expecting in-order frames so nothing more clever is required
+static unsigned int
+pts_track_count(const pts_track_t * const trk)
+{
+    return (trk->n - trk->last_n) & (PTS_TRACK_SIZE - 1);
+}
+
 static struct timeval pts_track_add_frame(pts_track_t * const trk, const AVFrame * const src)
 {
     const uint32_t n = pts_track_next_n(trk);
@@ -406,6 +441,12 @@ fmt_pixelformat(const struct v4l2_format * const fmt)
     return V4L2_TYPE_IS_MULTIPLANAR(fmt->type) ? fmt->fmt.pix_mp.pixelformat : fmt->fmt.pix.pixelformat;
 }
 
+static inline uint32_t
+buf_bytesused0(const struct v4l2_buffer * const buf)
+{
+    return V4L2_TYPE_IS_MULTIPLANAR(buf->type) ? buf->m.planes[0].bytesused : buf->bytesused;
+}
+
 static void
 init_format(V4L2Queue * const q, const uint32_t format_type)
 {
@@ -1469,12 +1510,24 @@ static int deint_v4l2m2m_dequeue_frame(V4L2Queue *queue, AVFrame* frame, int tim
 
     av_log(ctx->logctx, AV_LOG_TRACE, "<<< %s\n", __func__);
 
+    if (queue->eos) {
+        av_log(ctx->logctx, AV_LOG_TRACE, ">>> %s: EOS\n", __func__);
+        return AVERROR_EOF;
+    }
+
     avbuf = deint_v4l2m2m_dequeue_buffer(queue, timeout);
     if (!avbuf) {
         av_log(ctx->logctx, AV_LOG_DEBUG, "%s: No buffer to dequeue (timeout=%d)\n", __func__, timeout);
         return AVERROR(EAGAIN);
     }
 
+    if (V4L2_TYPE_IS_CAPTURE(avbuf->buffer.type)) {
+        if ((avbuf->buffer.flags & V4L2_BUF_FLAG_LAST) != 0)
+            queue->eos = 1;
+        if (buf_bytesused0(&avbuf->buffer) == 0)
+            return queue->eos ? AVERROR_EOF : AVERROR(EINVAL);
+    }
+
     // Fill in PTS and anciliary info from src frame
     pts_track_get_frame(&ctx->track, avbuf->buffer.timestamp, frame);
 
@@ -1697,6 +1750,20 @@ static int deint_v4l2m2m_filter_frame(AVFilterLink *link, AVFrame *in)
         else
             ctx->field_order = V4L2_FIELD_INTERLACED_BT;
 
+        {
+            struct v4l2_encoder_cmd ecmd = {
+                .cmd = V4L2_ENC_CMD_STOP
+            };
+            ctx->has_enc_stop = 0;
+            if (ioctl(ctx->fd, VIDIOC_TRY_ENCODER_CMD, &ecmd) == 0) {
+                av_log(ctx->logctx, AV_LOG_DEBUG, "Test encode stop succeeded\n");
+                ctx->has_enc_stop = 1;
+            }
+            else {
+                av_log(ctx->logctx, AV_LOG_DEBUG, "Test encode stop fail: %s\n", av_err2str(AVERROR(errno)));
+            }
+
+        }
     }
 
     ret = deint_v4l2m2m_enqueue_frame(output, in);
@@ -1705,6 +1772,41 @@ static int deint_v4l2m2m_filter_frame(AVFilterLink *link, AVFrame *in)
     return ret;
 }
 
+static int
+ack_inlink(AVFilterContext * const avctx, DeintV4L2M2MContextShared *const s,
+           AVFilterLink * const inlink)
+{
+    int instatus;
+    int64_t inpts;
+
+    if (ff_inlink_acknowledge_status(inlink, &instatus, &inpts) <= 0)
+        return 0;
+
+    s->drain      = instatus;
+    s->drain_pts  = inpts;
+    s->drain_state = DRAIN_TIMEOUT;
+
+    if (s->field_order == V4L2_FIELD_ANY) {  // Not yet started
+        s->drain_state = DRAIN_DONE;
+    }
+    else if (s->one_to_one) {
+        s->drain_state = DRAIN_LAST;
+    }
+    else if (s->has_enc_stop) {
+        struct v4l2_encoder_cmd ecmd = {
+            .cmd = V4L2_ENC_CMD_STOP
+        };
+        if (ioctl(s->fd, VIDIOC_ENCODER_CMD, &ecmd) == 0) {
+            av_log(avctx->priv, AV_LOG_DEBUG, "Do Encode stop\n");
+            s->drain_state = DRAIN_EOS;
+        }
+        else {
+            av_log(avctx->priv, AV_LOG_WARNING, "Encode stop fail: %s\n", av_err2str(AVERROR(errno)));
+        }
+    }
+    return 1;
+}
+
 static int deint_v4l2m2m_activate(AVFilterContext *avctx)
 {
     DeintV4L2M2MContext * const priv = avctx->priv;
@@ -1713,15 +1815,13 @@ static int deint_v4l2m2m_activate(AVFilterContext *avctx)
     AVFilterLink * const inlink = avctx->inputs[0];
     int n = 0;
     int cn = 99;
-    int instatus = 0;
-    int64_t inpts = 0;
     int did_something = 0;
 
     av_log(priv, AV_LOG_TRACE, "<<< %s\n", __func__);
 
     FF_FILTER_FORWARD_STATUS_BACK_ALL(outlink, avctx);
 
-    ff_inlink_acknowledge_status(inlink, &instatus, &inpts);
+    ack_inlink(avctx, s, inlink);
 
     if (!ff_outlink_frame_wanted(outlink)) {
         av_log(priv, AV_LOG_TRACE, "%s: Not wanted out\n", __func__);
@@ -1731,7 +1831,6 @@ static int deint_v4l2m2m_activate(AVFilterContext *avctx)
         AVFrame * frame = av_frame_alloc();
         int rv;
 
-again:
         recycle_q(&s->output);
         n = count_enqueued(&s->output);
 
@@ -1740,10 +1839,21 @@ again:
             return AVERROR(ENOMEM);
         }
 
-        rv = deint_v4l2m2m_dequeue_frame(&s->capture, frame, n > 4 ? 300 : 0);
+        rv = deint_v4l2m2m_dequeue_frame(&s->capture, frame,
+                                         drain_frame_expected(s->drain_state) || n > 4 ? 300 : 0);
         if (rv != 0) {
             av_frame_free(&frame);
-            if (rv != AVERROR(EAGAIN)) {
+            if (rv == AVERROR_EOF) {
+                av_log(priv, AV_LOG_DEBUG, "%s: --- DQ EOF\n", __func__);
+                s->drain_state = DRAIN_DONE;
+            }
+            else if (rv == AVERROR(EAGAIN)) {
+                if (s->drain_state != DRAIN_NONE) {
+                    av_log(priv, AV_LOG_DEBUG, "%s: --- DQ empty - drain done\n", __func__);
+                    s->drain_state = DRAIN_DONE;
+                }
+            }
+            else {
                 av_log(priv, AV_LOG_ERROR, ">>> %s: DQ fail: %s\n", __func__, av_err2str(rv));
                 return rv;
             }
@@ -1753,29 +1863,30 @@ again:
             // frame is always consumed by filter_frame - even on error despite
             // a somewhat confusing comment in the header
             rv = ff_filter_frame(outlink, frame);
-
-            if (instatus != 0) {
-                av_log(priv, AV_LOG_TRACE, "%s: eof loop\n", __func__);
-                goto again;
-            }
+            ++s->frames_tx;
 
             av_log(priv, AV_LOG_TRACE, "%s: Filtered: %s\n", __func__, av_err2str(rv));
             did_something = 1;
+
+            if (s->drain_state != DRAIN_NONE && pts_track_count(&s->track) == 0) {
+                av_log(priv, AV_LOG_DEBUG, "%s: --- DQ last - drain done\n", __func__);
+                s->drain_state = DRAIN_DONE;
+            }
         }
 
         cn = count_enqueued(&s->capture);
     }
 
-    if (instatus != 0) {
-        ff_outlink_set_status(outlink, instatus, inpts);
-        av_log(priv, AV_LOG_TRACE, ">>> %s: Status done: %s\n", __func__, av_err2str(instatus));
+    if (s->drain_state == DRAIN_DONE) {
+        ff_outlink_set_status(outlink, s->drain, s->drain_pts);
+        av_log(priv, AV_LOG_TRACE, ">>> %s: Status done: %s\n", __func__, av_err2str(s->drain));
         return 0;
     }
 
     recycle_q(&s->output);
     n = count_enqueued(&s->output);
 
-    while (n < 6) {
+    while (n < 6 && !s->drain) {
         AVFrame * frame;
         int rv;
 
@@ -1786,8 +1897,13 @@ again:
 
         if (frame == NULL) {
             av_log(priv, AV_LOG_TRACE, "%s: No frame\n", __func__);
+            if (!ack_inlink(avctx, s, inlink)) {
+                ff_inlink_request_frame(inlink);
+                av_log(priv, AV_LOG_TRACE, "%s: req frame\n", __func__);
+            }
             break;
         }
+        ++s->frames_rx;
 
         rv = deint_v4l2m2m_filter_frame(inlink, frame);
         av_frame_free(&frame);
@@ -1796,16 +1912,11 @@ again:
             return rv;
 
         av_log(priv, AV_LOG_TRACE, "%s: Q frame\n", __func__);
-        ++n;
-    }
-
-    if (n < 6) {
-        ff_inlink_request_frame(inlink);
         did_something = 1;
-        av_log(priv, AV_LOG_TRACE, "%s: req frame\n", __func__);
+        ++n;
     }
 
-    if (n > 4 && ff_outlink_frame_wanted(outlink)) {
+    if ((n > 4 || s->drain) && ff_outlink_frame_wanted(outlink)) {
         ff_filter_set_ready(avctx, 1);
         did_something = 1;
         av_log(priv, AV_LOG_TRACE, "%s: ready\n", __func__);
@@ -1884,7 +1995,18 @@ static av_cold int deint_v4l2m2m_init(AVFilterContext *avctx)
 
 static av_cold int scale_v4l2m2m_init(AVFilterContext *avctx)
 {
-    return common_v4l2m2m_init(avctx, FILTER_V4L2_SCALE);
+    int rv;
+    DeintV4L2M2MContext * priv;
+    DeintV4L2M2MContextShared * ctx;
+
+    if ((rv = common_v4l2m2m_init(avctx, FILTER_V4L2_SCALE)) != 0)
+        return rv;
+
+    priv = avctx->priv;
+    ctx = priv->shared;
+
+    ctx->one_to_one = 1;
+    return 0;
 }
 
 static void deint_v4l2m2m_uninit(AVFilterContext *avctx)
@@ -1892,6 +2014,8 @@ static void deint_v4l2m2m_uninit(AVFilterContext *avctx)
     DeintV4L2M2MContext *priv = avctx->priv;
     DeintV4L2M2MContextShared *ctx = priv->shared;
 
+    av_log(priv, AV_LOG_VERBOSE, "Frames Rx: %u, Frames Tx: %u\n",
+           ctx->frames_rx, ctx->frames_tx);
     ctx->done = 1;
     ctx->logctx = NULL;  // Log to NULL works, log to missing crashes
     pts_track_uninit(&ctx->track);
-- 
2.38.1

